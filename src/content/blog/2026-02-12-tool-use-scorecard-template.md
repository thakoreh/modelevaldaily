---
title: 'Tool‑Use Scorecard Template: <Docs Task>'
description: 'Template for tool‑use evals with rubric, scores, and doc alignment notes.'
pubDate: '2026-02-12'
heroImage: '../../assets/blog-placeholder-2.jpg'
---

This is a **tool‑use scorecard template**. Duplicate this file and replace placeholders with a real docs‑driven task.

## Task context
- **Scenario:** <setup task>
- **Goal:** <what must be configured>
- **Constraints:** <security, env, tooling>

## Prompt
```
<Paste the exact prompt>
```

## Rubric (10 points)
- **4 pts** — <correct CLI commands>
- **3 pts** — <verification step>
- **3 pts** — <handler stub or config output>

## Results
| Model | Score | Notes |
| --- | --- | --- |
| <Model A> | <x.x> | <Strengths/weaknesses> |
| <Model B> | <x.x> | <Strengths/weaknesses> |
| <Model C> | <x.x> | <Strengths/weaknesses> |

## What “great” looked like
- **Minimal flow:** <short list of steps>
- **Verification:** <explicit step>

## Operator analysis
- **Why this task matters:** <security/ops impact>
- **Common failure:** <missed verification>
- **Winner rationale:** <why top model won>

## Repro steps
1. Use the exact prompt above.
2. Score against the rubric.
3. Verify output against the official docs.

**Related:** link back to the daily scorecard for this date.